{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import random\n",
    "import keras\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(path, label, seq_length):\n",
    "    data_list = []\n",
    "    for record in SeqIO.parse(path, \"fasta\"):\n",
    "        info_tag = record.id\n",
    "        chromID = info_tag.split(\"_\")[0]\n",
    "        chromSeq = (str(record.seq)).upper()\n",
    "        if len(chromSeq) < seq_length:\n",
    "            continue\n",
    "        offset_start = int((len(chromSeq)-seq_length)/2.0)\n",
    "        chromSeq_trimmed = chromSeq[offset_start : offset_start+seq_length]\n",
    "        data_list.append((chromSeq_trimmed, label, chromID, info_tag))\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, test):\n",
    "    for data_point in dataset:\n",
    "        chromID = data_point[2]\n",
    "        if chromID == \"chr9\":\n",
    "            test.append(data_point)\n",
    "\n",
    "def dataset2onehot(dataset, shuffle=True):\n",
    "    nucleotides = [\"A\", \"T\", \"C\", \"G\"]\n",
    "    def seq2onehot(seq):\n",
    "        onehot_list = []\n",
    "        for nuc in seq:\n",
    "            if nuc == \"N\":\n",
    "                onehot = [0.25 for _ in range(len(nucleotides))]\n",
    "                onehot_list.append(onehot)\n",
    "            else:\n",
    "                onehot = [0 for _ in range(len(nucleotides))]\n",
    "                onehot[nucleotides.index(nuc)] = 1\n",
    "                onehot_list.append(onehot)\n",
    "        return onehot_list\n",
    "    \n",
    "    def rc(seq):\n",
    "        return str((Seq(seq)).reverse_complement())\n",
    "    \n",
    "    onehot_dataset = []\n",
    "    for (seq, label, chromID, tag_info) in dataset:\n",
    "        onehot_dataset.append((seq2onehot(seq), label, (tag_info, \"+\")))\n",
    "        onehot_dataset.append((seq2onehot(rc(seq)), label, (tag_info, \"-\")))\n",
    "    \n",
    "    if shuffle:\n",
    "        random.shuffle(onehot_dataset)\n",
    "    \n",
    "    x_list, y_list, info_list = [], [], [] \n",
    "    for (x, y, info) in onehot_dataset:\n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "        info_list.append(info)\n",
    "    return np.array(x_list), np.array(y_list), info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /gpfs/data01/glasslab/home/zes017/.conda/envs/zs-tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /gpfs/data01/glasslab/home/zes017/.conda/envs/zs-tensorflow/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Data: IL4 Model: IL4 auROC: 0.893664 auPRC: 0.900985\n",
      "Data: IL4 Model: IL4Induced auROC: 0.840716 auPRC: 0.845858\n",
      "Data: IL4 Model: Induced_vs_noninduced auROC: 0.381604 auPRC: 0.470984\n",
      "Data: IL4Induced Model: IL4 auROC: 0.915187 auPRC: 0.909545\n",
      "Data: IL4Induced Model: IL4Induced auROC: 0.919305 auPRC: 0.921631\n",
      "Data: IL4Induced Model: Induced_vs_noninduced auROC: 0.560938 auPRC: 0.610653\n",
      "Data: Induced_vs_noninduced Model: IL4 auROC: 0.458268 auPRC: 0.313658\n",
      "Data: Induced_vs_noninduced Model: IL4Induced auROC: 0.623467 auPRC: 0.434205\n",
      "Data: Induced_vs_noninduced Model: Induced_vs_noninduced auROC: 0.796493 auPRC: 0.672665\n"
     ]
    }
   ],
   "source": [
    "experiment_path = {\"IL4\": [\"./data/model1_IL4Enhancer/C57Bl6_IL4Enhancers.positive.fa\",\n",
    "                           \"./data/model1_IL4Enhancer/C57Bl6_IL4Enhancers.negative.fa\",\n",
    "                           \"../../new_project/tmp/IL4_modelJson_tmp.json\", \n",
    "                           \"../../new_project/tmp/IL4_modelWeights.h5\"],\n",
    "                  \"IL4Induced\": [\"./data/model2_IL4InducedEnhancer/Strains_IL4InducedEnhancers.positive.fa\",\n",
    "                                 \"./data/model2_IL4InducedEnhancer/Strains_IL4InducedEnhancers.negative.fa\",\n",
    "                                 \"../../new_project/tmp/IL4Induced_modelJson_tmp.json\", \n",
    "                                 \"../../new_project/tmp/IL4Induced_modelWeights.h5\"],\n",
    "                  \"Induced_vs_noninduced\": [\"./data/model3_IL4induced_vs_noninduced/Strains_IL4InducedEnhancers.vs.C57_basalNoninducedEnhancers.positive.fa\",\n",
    "                                            \"./data/model3_IL4induced_vs_noninduced/Strains_IL4InducedEnhancers.vs.C57_basalNoninducedEnhancers.negative.fa\",\n",
    "                                            \"../../new_project/tmp/IL4Induced_vs_noninduced_modelJson_tmp.json\", \n",
    "                                            \"../../new_project/tmp/IL4Induced_vs_noninduced_modelWeights.h5\"]}\n",
    "\n",
    "for experiment_name in experiment_path:\n",
    "    pos_data_path, neg_data_path, _, _ = experiment_path[experiment_name]\n",
    "    pos_data = data_prep(pos_data_path, 1, seq_size)\n",
    "    neg_data = data_prep(neg_data_path, 0, seq_size)\n",
    "\n",
    "    test_raw = []\n",
    "    create_dataset(pos_data, test_raw)\n",
    "    create_dataset(neg_data, test_raw)\n",
    "    x_test, y_test, info_test = dataset2onehot(test_raw)\n",
    "    \n",
    "    for experiment_name_for_model in experiment_path:\n",
    "        _, _, model_json, model_weights = experiment_path[experiment_name_for_model]\n",
    "        model = model_from_json(open(model_json).read())\n",
    "        model.load_weights(model_weights)\n",
    "        y_pred = model.predict(x_test, batch_size=512, verbose=0)\n",
    "        roc_value = roc_auc_score(y_test, y_pred)\n",
    "        pr_value = average_precision_score(y_test, y_pred)\n",
    "        print (\"Data: %s Model: %s auROC: %f auPRC: %f\" %(experiment_name, experiment_name_for_model, roc_value, pr_value)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
